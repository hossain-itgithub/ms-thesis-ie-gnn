Class counts: {'company': 530, 'date': 635, 'address': 1233, 'total': 1341, 'other': 24088}
Model summary:
===================================================================================================================
Layer (type:depth-idx)                   Input Shape               Output Shape              Param #
===================================================================================================================
ConfigurableGNN                          [286, 776]                [286, 5]                  --
├─ModuleList: 1-1                        --                        --                        --
│    └─GCNConv: 2-1                      [286, 776]                [286, 256]                256
│    │    └─Linear: 3-1                  [286, 776]                [286, 256]                198,656
│    │    └─SumAggregation: 3-2          [568, 256]                [286, 256]                --
│    └─GCNConv: 2-2                      [286, 256]                [286, 256]                256
│    │    └─Linear: 3-3                  [286, 256]                [286, 256]                65,536
│    │    └─SumAggregation: 3-4          [568, 256]                [286, 256]                --
│    └─GCNConv: 2-3                      [286, 256]                [286, 256]                256
│    │    └─Linear: 3-5                  [286, 256]                [286, 256]                65,536
│    │    └─SumAggregation: 3-6          [568, 256]                [286, 256]                --
│    └─GCNConv: 2-4                      [286, 256]                [286, 256]                256
│    │    └─Linear: 3-7                  [286, 256]                [286, 256]                65,536
│    │    └─SumAggregation: 3-8          [568, 256]                [286, 256]                --
├─ModuleList: 1-2                        --                        --                        --
│    └─GATConv: 2-5                      [286, 256]                [286, 256]                768
│    │    └─Linear: 3-9                  [286, 256]                [286, 256]                65,536
│    │    └─SumAggregation: 3-10         [568, 1, 256]             [286, 1, 256]             --
│    └─GATConv: 2-6                      [286, 256]                [286, 256]                768
│    │    └─Linear: 3-11                 [286, 256]                [286, 256]                65,536
│    │    └─SumAggregation: 3-12         [568, 1, 256]             [286, 1, 256]             --
│    └─GATConv: 2-7                      [286, 256]                [286, 256]                768
│    │    └─Linear: 3-13                 [286, 256]                [286, 256]                65,536
│    │    └─SumAggregation: 3-14         [568, 1, 256]             [286, 1, 256]             --
│    └─GATConv: 2-8                      [286, 256]                [286, 256]                768
│    │    └─Linear: 3-15                 [286, 256]                [286, 256]                65,536
│    │    └─SumAggregation: 3-16         [568, 1, 256]             [286, 1, 256]             --
├─SpatialAttentionLayer: 1-3             [286, 256]                [286, 256]                --
│    └─Linear: 2-9                       [286, 256]                [286, 256]                65,792
│    └─Linear: 2-10                      [286, 256]                [286, 256]                65,792
│    └─Linear: 2-11                      [286, 256]                [286, 256]                65,792
├─Linear: 1-4                            [286, 256]                [286, 5]                  1,285
===================================================================================================================
Total params: 860,165
Trainable params: 860,165
Non-trainable params: 0
Total mult-adds (Units.MEGABYTES): 244.84
===================================================================================================================
Input size (MB): 0.89
Forward/backward pass size (MB): 6.45
Params size (MB): 3.42
Estimated Total Size (MB): 10.77
===================================================================================================================
Epoch: 20, Loss: 0.4075579830380373, Accuracy: 0.8723541883781939
Epoch: 40, Loss: 0.37321203727592794, Accuracy: 0.881338268588062
Epoch: 60, Loss: 0.3365819040657014, Accuracy: 0.8876271247349696
Epoch: 80, Loss: 0.3079497238924337, Accuracy: 0.8928378912566931
Epoch: 100, Loss: 0.2802859699541284, Accuracy: 0.8983361483451324
Epoch: 120, Loss: 0.2650518692279047, Accuracy: 0.9007079455205376
Epoch: 140, Loss: 0.24916167245354764, Accuracy: 0.904768749775398
Epoch: 160, Loss: 0.23631017920813818, Accuracy: 0.9073202285550005
Epoch: 180, Loss: 0.2221727224514466, Accuracy: 0.9108060516764294
Epoch: 200, Loss: 0.21703301017829615, Accuracy: 0.9107701153555899
Epoch: 220, Loss: 0.19745150202697562, Accuracy: 0.916555863010745
Epoch: 240, Loss: 0.2193700067641199, Accuracy: 0.911237287526503
Epoch: 260, Loss: 0.1965916981530744, Accuracy: 0.9157652639522765
Epoch: 280, Loss: 0.16925347838983978, Accuracy: 0.9235634455744421
Epoch: 300, Loss: 0.1908569965482682, Accuracy: 0.9192510870737054
Epoch: 320, Loss: 0.17084499113550483, Accuracy: 0.9238149998203184
Epoch: 340, Loss: 0.215313519502795, Accuracy: 0.9148668559312898
Epoch: 360, Loss: 0.1899524762533432, Accuracy: 0.9187839149027922
Epoch: 380, Loss: 0.20093639062125554, Accuracy: 0.9149746648938082
Epoch: 400, Loss: 0.19905137929112413, Accuracy: 0.9175261436734107
Epoch: 420, Loss: 0.15236198544040208, Accuracy: 0.9286304668128077
Epoch: 440, Loss: 0.16994062528129697, Accuracy: 0.9237431271786395
Epoch: 460, Loss: 0.15491590666216473, Accuracy: 0.9281632946418945
Epoch: 480, Loss: 0.13473668957287951, Accuracy: 0.9349552592805549
Epoch: 500, Loss: 0.14083009577074715, Accuracy: 0.9330506342760628
Epoch: 520, Loss: 0.13454409140024998, Accuracy: 0.9359974125848995
Epoch: 540, Loss: 0.14283359206693116, Accuracy: 0.932080353613397
Epoch: 560, Loss: 0.14030368770508803, Accuracy: 0.9347037050346786
Epoch: 580, Loss: 0.1229107418610144, Accuracy: 0.9403457074064757
Epoch: 600, Loss: 0.10943425929014997, Accuracy: 0.9451252380781255
Epoch: 620, Loss: 0.10596454238822293, Accuracy: 0.9461314550616308
Epoch: 640, Loss: 0.10915274600418963, Accuracy: 0.9454127286448414
Epoch: 660, Loss: 0.10937416215622148, Accuracy: 0.9444424479821756
Epoch: 680, Loss: 0.1044569290423578, Accuracy: 0.9464189456283466
Epoch: 700, Loss: 0.11074736720138742, Accuracy: 0.9460955187407913
Epoch: 720, Loss: 0.11793700825105342, Accuracy: 0.9426096956193625
Epoch: 740, Loss: 0.10342440687755282, Accuracy: 0.9478923347827649
Epoch: 760, Loss: 0.10172056940983432, Accuracy: 0.9483235706328386
Epoch: 780, Loss: 0.10080346707687822, Accuracy: 0.9492219786538254
Epoch: 800, Loss: 0.10008042256614959, Accuracy: 0.949114169691307
Epoch: 820, Loss: 0.1295757541187512, Accuracy: 0.9418909692025731
Epoch: 840, Loss: 0.09317110244964444, Accuracy: 0.9520250116793043
Epoch: 860, Loss: 0.08498343447035597, Accuracy: 0.9544686814963884
Epoch: 880, Loss: 0.09919552427045135, Accuracy: 0.9511266036583175
Epoch: 900, Loss: 0.0877041603878949, Accuracy: 0.9543968088547095
Epoch: 920, Loss: 0.10435734695011331, Accuracy: 0.9488266791245912
Epoch: 940, Loss: 0.08284072616938935, Accuracy: 0.955582707442412
Epoch: 960, Loss: 0.09381455006872037, Accuracy: 0.9531390376253279
Epoch: 980, Loss: 0.08839373455144638, Accuracy: 0.9543249362130305
Epoch: 1000, Loss: 0.07893213582073533, Accuracy: 0.9572717145218672
Final Evaluation Loss: 0.07554740863021954, Accuracy: 0.958852912638804
Final Classification Report:
              precision    recall  f1-score   support

     company       0.52      0.47      0.50       530
        date       0.76      0.81      0.78       635
     address       0.87      0.92      0.90      1233
       total       0.88      0.87      0.87      1341
       other       0.98      0.98      0.98     24088

    accuracy                           0.96     27827
   macro avg       0.80      0.81      0.81     27827
weighted avg       0.96      0.96      0.96     27827

Test Loss: 0.5240837671883303, Test Accuracy: 0.9045698077529152
Test Classification Report:
              precision    recall  f1-score   support

     company       0.48      0.43      0.45       296
        date       0.56      0.50      0.53       352
     address       0.72      0.73      0.73       709
       total       0.56      0.40      0.47       722
       other       0.94      0.96      0.95     13786

    accuracy                           0.90     15865
   macro avg       0.65      0.60      0.62     15865
weighted avg       0.90      0.90      0.90     15865

Model saved to logs/20240713_232548/invoice_gnn.pth
Model parameters saved to logs/20240713_232548/model_params.txt
Errors logged.
Percentage of erroneous files: 16.96%
